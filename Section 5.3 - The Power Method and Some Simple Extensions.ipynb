{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "together-disability",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 5.3: The Power Method and Some Simple Extensions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-murder",
   "metadata": {},
   "source": [
    "Let $A \\in \\mathbb{C}^{n \\times n}$ be a matrix with _linearly independent_ eigenvectors\n",
    "\n",
    "$$\n",
    "v_1, \\ldots, v_n\n",
    "$$\n",
    "\n",
    "and corresponding eigenvalues\n",
    "\n",
    "$$\n",
    "\\lambda_1, \\ldots, \\lambda_n\n",
    "$$\n",
    "\n",
    "(i.e., $A v_i = \\lambda_i v_i$, for $i=1,\\ldots,n$) ordered such that\n",
    "\n",
    "$$\n",
    "|\\lambda_1| \\ge |\\lambda_2| \\ge \\cdots \\ge |\\lambda_n|.\n",
    "$$\n",
    "\n",
    "We say that $A$ has a **dominant eigenvalue** if\n",
    " \n",
    "$$\n",
    "|\\lambda_1| > |\\lambda_2|.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-philosophy",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-insight",
   "metadata": {},
   "source": [
    "## The Power Method\n",
    "\n",
    "The basic idea of the **power method** is to pick a vector $q \\in \\mathbb{C}^n$ and compute the sequence\n",
    "\n",
    "$$\n",
    "q,\\ A q,\\ A^2 q,\\ A^3 q,\\ \\ldots.\n",
    "$$\n",
    "\n",
    "Since the eigenvectors $v_1,\\ldots,v_n$ form a basis for $\\mathbb{C}^n$, we have that\n",
    "\n",
    "$$\n",
    "q = c_1 v_1 + \\cdots + c_n v_n.\n",
    "$$\n",
    "\n",
    "For a random $q$, we expect $c_1 \\ne 0$.\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "A q\n",
    "&= c_1 A v_1 + \\cdots + c_n A v_n \\\\\n",
    "&= c_1 \\lambda_1 v_1 + \\cdots + c_n \\lambda_n v_n\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "A^2 q\n",
    "&= c_1 \\lambda_1 A v_1 + \\cdots + c_n \\lambda_n A v_n \\\\\n",
    "&= c_1 \\lambda_1^2 v_1 + \\cdots + c_n \\lambda_n^2 v_n.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In general, we have\n",
    "\n",
    "$$\n",
    "A^j q = c_1 \\lambda_1^j v_1 + \\cdots + c_n \\lambda_n^j v_n\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\frac{A^j q}{\\lambda_1^j} = c_1 v_1 + c_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^j v_2 + \\cdots + c_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^j v_n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-affect",
   "metadata": {},
   "source": [
    "Letting\n",
    "\n",
    "$$\n",
    "q_j = \\frac{A^j q}{\\lambda_1^j},\n",
    "$$\n",
    "\n",
    "we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\| q_j - c_1 v_1 \\|\n",
    "&= \\left\\| c_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^j v_2 + \\cdots + c_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^j v_n \\right\\| \\\\\n",
    "&\\le |c_2| \\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^j \\|v_2\\| + \\cdots + |c_n| \\left|\\frac{\\lambda_n}{\\lambda_1}\\right|^j \\|v_n\\| \\\\\n",
    "&\\le \\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^j \\big(|c_2| \\|v_2\\| + \\cdots + |c_n| \\|v_n\\|\\big).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Now suppose $|\\lambda_1| > |\\lambda_2|$. Then\n",
    "\n",
    "$$\n",
    "\\left|\\frac{\\lambda_2}{\\lambda_1}\\right| < 1.\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^j \\to 0 \\quad \\text{as} \\ j \\to \\infty.\n",
    "$$\n",
    "\n",
    "Thus, $\\| q_j - c_1 v_1 \\| \\to 0$ as $j \\to \\infty$, so we conclude that\n",
    "\n",
    "$$\n",
    "q_j \\to c_1 v_1 \\quad \\text{as $j \\to \\infty$.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-israeli",
   "metadata": {},
   "source": [
    "The rate of the convergence of the power method is generally linear ($\\|q_{j+1} - c_1 v_1\\| \\approx r \\|q_j - c_1 v_1\\|$ for all $j$ sufficiently large) with convergence ratio\n",
    "\n",
    "$$\n",
    "r = \\left|\\frac{\\lambda_2}{\\lambda_1}\\right|.\n",
    "$$\n",
    "\n",
    "Thus, the larger the gap between $|\\lambda_1|$ and $|\\lambda_2|$, the smaller the convergence ratio and the faster the convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-reader",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-hormone",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Since we usually do not know $\\lambda_1$ while running the power method, we will not be able to compute $q_j = A^j q/\\lambda_1^j$. However, it is important that we scale $A^j q$ since $\\|A^j q\\| \\to \\infty$ if $|\\lambda_1| > 1$ and $\\|A^j q\\| \\to 0$ if $|\\lambda_1| < 1$.\n",
    "\n",
    "A simple choice is to scale $A^j q$ so that its largest entry is equal to one. Thus, we let\n",
    "\n",
    "$$\n",
    "q_{j+1} = \\frac{A q_j}{s_{j+1}},\n",
    "$$\n",
    "\n",
    "where $s_{j+1}$ is the component of $A q_j$ which has the largest absolute value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-advantage",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-parameter",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "Given $q_0 \\in \\mathbb{C}^n$, we iterate\n",
    "\n",
    "1. $\\hat{q} = A q_j$\n",
    "\n",
    "2. $s_{j+1} =$ entry of $\\hat{q}$ with largest absolute value\n",
    "\n",
    "3. $q_{j+1} \\gets \\hat{q}/s_{j+1}$\n",
    "\n",
    "for $j = 0, 1, 2, \\ldots$.\n",
    "\n",
    "Then $q_j$ approaches a multiple of $v_1$ and $s_j$ approaches the eigenvalue $\\lambda_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-louisiana",
   "metadata": {},
   "source": [
    "If $A$ is a dense $n \\times n$ matrix, then each iteration of this algorithm will require $2n^2 + O(n)$ flops. However, if $A$ is sparse and has at most $k$ nonzeros on each row, then each iteration will require approximately $2 k n$ flops. Therefore, the power method is very well suited for computing the dominant eigenvalue and associated eigenvector of large sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-produce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-fighter",
   "metadata": {},
   "source": [
    "## `power_method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorrect-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, SparseArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "passive-serial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power_method (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function scale!(q)\n",
    "    maxval, idx = maximum((abs(q[i]),i) for i=1:length(q))\n",
    "    s = q[idx]\n",
    "    q ./= s\n",
    "    return s\n",
    "end\n",
    "\n",
    "function power_method(A; tol=sqrt(eps())/2, maxiter=100_000)\n",
    "    m, n = size(A)\n",
    "    n == m || error(\"Matrix must be square.\")\n",
    "    \n",
    "    q = randn(n)\n",
    "    s = scale!(q)\n",
    "\n",
    "    qold = similar(q)\n",
    "    tmp = similar(q)\n",
    "\n",
    "    k = 0\n",
    "    done = false\n",
    "    while !done && k < maxiter\n",
    "        k += 1\n",
    "        copy!(qold, q)        # qold = q\n",
    "        mul!(q, A, qold)      # q = A*qold\n",
    "        s = scale!(q)         # q = q/s\n",
    "        tmp .= q .- qold\n",
    "        done = norm(tmp)/(norm(q) + 1) <= tol\n",
    "    end\n",
    "\n",
    "    if done\n",
    "        println(\"Converged after $k iterations.\")\n",
    "    else\n",
    "        println(\"Failed to converge.\")\n",
    "    end\n",
    "\n",
    "    return s, q\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "second-syndication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnz(A) = 10278\n",
      "r = 0.7514960512238529\n",
      "Converged after 71 iterations.\n",
      "  0.000924 seconds (48 allocations: 25.031 KiB)\n",
      "norm(A * q - s * q) = 4.6081284244072415e-7\n"
     ]
    }
   ],
   "source": [
    "n = 1_000\n",
    "k = 10\n",
    "density = (k - 1)/n    # density = (k*n - n)/n^2\n",
    "\n",
    "A = triu(sprand(n, n, density), 1)\n",
    "A = A + A' + I\n",
    "\n",
    "# Expect nnz(A) ≈ k*n\n",
    "@show nnz(A)\n",
    "\n",
    "if n <= 1000\n",
    "    λ = eigvals(Matrix(A))\n",
    "    abseig = abs.(λ) |> sort\n",
    "    r = abseig[end-1]/abseig[end]\n",
    "    @show r\n",
    "end\n",
    "\n",
    "@time s, q = power_method(A)\n",
    "\n",
    "@show norm(A*q - s*q);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-drunk",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-polyester",
   "metadata": {},
   "source": [
    "## Google PageRank Algorithm\n",
    "\n",
    "Google uses its [PageRank](https://en.wikipedia.org/wiki/PageRank) algorithm to determine its ranking of webpages in search results.\n",
    "\n",
    "The [Google matrix](https://en.wikipedia.org/wiki/Google_matrix) represents how webpages on the Internet link to one another.\n",
    "\n",
    "PageRank uses the power method to compute the dominant eigenvector of the Google matrix, and this dominant eigenvector is then used to rank the importance of webpages.\n",
    "\n",
    "By design, the convergence ratio of the Google matrix is\n",
    "\n",
    "$$\n",
    "\\left|\\frac{\\lambda_2}{\\lambda_1}\\right| = 0.85,\n",
    "$$\n",
    "\n",
    "so the number of power method iterations is reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-duplicate",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-vietnam",
   "metadata": {},
   "source": [
    "## Inverse Power Method\n",
    "\n",
    "Let $A \\in \\mathbb{C}^{n \\times n}$ be nonsingular. Since $A$ is nonsingular, all of its eigenvalues are nonzero. \n",
    "\n",
    "Since\n",
    "\n",
    "$$\n",
    "A v = \\lambda v \\quad \\implies \\quad A^{-1} v = \\lambda^{-1} v,\n",
    "$$\n",
    "\n",
    "the eigenvalues of $A^{-1}$ are $\\lambda_1^{-1},\\ldots,\\lambda_n^{-1}$ and the corresponding eigenvectors are $v_1,\\ldots,v_n$.\n",
    "\n",
    "Since\n",
    "\n",
    "$$\n",
    "|\\lambda_1| \\ge |\\lambda_2| \\ge \\cdots \\ge |\\lambda_n|,\n",
    "$$\n",
    "\n",
    "we have that\n",
    "\n",
    "$$\n",
    "\\left|\\lambda_1^{-1}\\right| \\le \\left|\\lambda_2^{-1}\\right| \\le \\cdots \\le \\left|\\lambda_n^{-1}\\right|.\n",
    "$$\n",
    "\n",
    "If $|\\lambda_{n-1}| > |\\lambda_n|$, then $\\left|\\lambda_n^{-1}\\right| >  \\left|\\lambda_{n-1}^{-1}\\right|$, so the **inverse power method**,\n",
    "\n",
    "$$\n",
    "q,\\ A^{-1} q,\\ A^{-2} q,\\ A^{-3} q,\\ \\ldots,\n",
    "$$\n",
    "\n",
    "will generate a sequence $q_j$ that converges to a multiple of $v_n$ (i.e., the eigenvector corresponding to the _smallest_ eigenvalue of $A$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-debate",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
