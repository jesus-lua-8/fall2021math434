{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating-point arithmetic\n",
    "\n",
    "Real numbers are stored on a computer following the IEEE floating-point standard:\n",
    "\n",
    "1. **half precision** using 16 bits (Julia type: `Float16`)\n",
    "2. **single precision** using 32 bits (Julia type: `Float32`)\n",
    "3. **double precision** using 64 bits (Julia type: `Float64`)\n",
    "\n",
    "Julia also has an **arbitrary precision** floating-point data type called `BigFloat`. It is excellent if you need more precision, but it is also much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "subtypes(Real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtypes(AbstractFloat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of IEEE double floating-point format (`Float64`)\n",
    "\n",
    "Suppose $x$ is a floating-point number stored in the following 64-bits:\n",
    "\n",
    "| 1 | 2 | $\\cdots$ | 12 | 13 | $\\cdots$ | 64 |\n",
    "|:-:|:-:|:--------:|:--:|:--:|:--------:|:--:|\n",
    "|$s$|$e_{10}$| $\\cdots$ |$e_0$|$f_1$|$\\cdots$|$f_{52}$|\n",
    "\n",
    "- 1 bit $s$ represents the **sign**\n",
    "- 11 bits $e_{10} \\cdots e_{0}$ represent the **exponent**\n",
    "- 52 bits $f_1 \\cdots f_{52}$ represent the **fraction** (a.k.a. the mantissa or significand)\n",
    "\n",
    "Then\n",
    "\n",
    "$$ x = (-1)^s \\left[1.f_1 \\cdots f_{52}\\right]_2 \\times 2^{(e-1023)}.$$\n",
    "\n",
    "Notes: \n",
    "\n",
    "- $x$ is **normalized** to have its first digit nonzero.\n",
    "- $e = \\left[e_{10} \\cdots e_{0}\\right]_2 = e_{10} 2^{10} + \\cdots + e_1 2^1 + e_0 2^0 \\in \\left[0, 2^{11}-1\\right] = [0, 2047]$\n",
    "- $e = 0$ and $e = 2047$ are reserved for special floating-point values, so \n",
    "\n",
    "$$e \\in [1, 2046]$$\n",
    "\n",
    "- the \"$-1023$\" in the exponent is called the **bias**:  $e-1023 \\in [-1022,1023]$\n",
    "- $\\left[1.f_1 \\cdots f_{52}\\right]_2 = 1 + \\frac{f_1}{2^1} + \\frac{f_2}{2^2} + \\cdots + \\frac{f_{52}}{2^{52}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "x & = -[1.101101]_2 \\times 2^{(1026-1023)} \\\\\n",
    "  & = -[1.101101]_2 \\times 2^{3} \\\\\n",
    "  & = -[1101.101]_2 \\\\\n",
    "  & = -\\left(1 \\cdot 8 + 1 \\cdot 4 + 0 \\cdot 2 + 1 \\cdot 1 + 1 \\cdot \\frac{1}{2} + 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{8}\\right)  \\\\\n",
    "  & = -13.625\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "?bitstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = -13.625\n",
    "bitstring(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "function bits(x)\n",
    "    foo = bitstring(x)\n",
    "    s = foo[1]\n",
    "    e = foo[2:12]\n",
    "    f = foo[13:64]\n",
    "    s, e, f\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "0b10000000010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Int(0b10000000010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Even if a number can be represented exactly in base-10 with a finite number of digits, it may require an infinite number of digits in base-2.\n",
    "\n",
    "$$\n",
    "0.1 = \\left[0.000110011001\\ldots\\right]_2 = \\left[1.\\overline{1001}\\right]_2 \\times 2^{-4}\n",
    "$$\n",
    "\n",
    "Therefore, $0.1$ cannot be represented exactly as a floating-point number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = 0.1\n",
    "bits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Int(0b01111111011) - 1023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = 0.1\n",
    "big(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limits of floating-point numbers\n",
    "\n",
    "- **Largest** `Float64` $= \\left(2 - 2^{-52}\\right) \\times 2^{1023} \\approx 2 \\times 10^{308}$\n",
    "- **Smallest positive normalized** `Float64` $= 2^{-1022} \\approx 2 \\times 10^{-308}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = (2.0 - 2.0^-52)*2.0^1023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = 2.0^-1022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bits(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IEEE floating-point standard also allows **de-normalized** numbers that are smaller than `2.0^-1022`. De-normalized floats are represented by $e = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's compute the smallest Float64 that is not zero\n",
    "\n",
    "using Printf\n",
    "\n",
    "e = -1022\n",
    "x = 2.0^e\n",
    "\n",
    "while x != 0.0\n",
    "    @printf \"%24.16e = 2.0^(%5d)\\n\" x e\n",
    "    x /= 2.0\n",
    "    e -= 1\n",
    "end\n",
    "\n",
    "x, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "2.0^-1074, 2.0^-1075"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore:\n",
    "\n",
    "- **Smallest positive de-normalized** `Float64` $= 2^{-1074} \\approx 5 \\times 10^{-324}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bits(2.0^-1074)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other special floats\n",
    "\n",
    "- `0.0` and `-0.0`: $$e_{10} \\cdots e_0 = 0 \\cdots 0 \\quad \\text{and} \\quad f_1 \\cdots f_{52} = 0 \\cdots 0$$\n",
    "- `Inf` and `-Inf`: $$e_{10} \\cdots e_0 = 1 \\cdots 1 \\quad \\text{and} \\quad f_1 \\cdots f_{52} = 0 \\cdots 0$$\n",
    "- `NaN` (not-a-number): $$e_{10} \\cdots e_0 = 1 \\cdots 1 \\quad \\text{and} \\quad f_1 \\cdots f_{52} \\neq 0$$\n",
    "\n",
    "From [Julia Manual: Mathematical Operations and Elementary Functions](https://docs.julialang.org/en/v1/manual/mathematical-operations/):\n",
    "\n",
    "- `Inf` is equal to itself and greater than everything else except `NaN`.\n",
    "- `-Inf` is equal to itself and less then everything else except `NaN`.\n",
    "- `NaN` is not equal to, not less than, and not greater than anything, including itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bits(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bits(-0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bits(Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bits(-Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bits(NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "1.0*0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "-1.0*0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "1.0/0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "-1.0/0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "1.0/Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "-1.0/Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "0.0/0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "-0.0 < 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine epsilon `eps(Float64)` and the unit roundoff $\\eta$\n",
    "\n",
    "- `1.0 + eps(Float64)` is the first `Float64` that is larger than `1.0`\n",
    "\n",
    "$$\\mathtt{eps(Float64)} = 2^{-52} \\approx 2.2 \\times 10^{-16}$$\n",
    "\n",
    "- $\\eta = $ `eps(Float64)/2.0` is the largest possible relative error due to roundoff\n",
    "\n",
    "$$\\eta = 2^{-53} \\approx 1.1 \\times 10^{-16}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "eps(Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "1.0 + eps(Float64) > 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "1.0 + eps(Float64)/2.0 > 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundoff error example\n",
    "\n",
    "Suppose we are using a base-10 floating-point system with 4 significant digits, using `RoundNearest`:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\left( 1.112 \\times 10^1 \\right) \\times \\left( 1.112 \\times 10^2 \\right)\n",
    "& = 1.236544 \\times 10^3 \\\\\n",
    "& \\rightarrow 1.237 \\times 10^3 = 1237\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "The absolute error is $1237 - 1236.544 = 0.456$.\n",
    "\n",
    "The relative error is $$\\frac{0.456}{1236.544} \\approx 0.0004 = 0.04 \\%$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the effect of roundoff error\n",
    "\n",
    "η = eps(Float32)/2.0              # Compute the unit roundoff for Float32\n",
    "\n",
    "x = range(-10, 10, length=10000)  # 10000-element Array{Float64,1} from -10 to 10\n",
    "y = Float32.(x)                   # Convert x to Float32\n",
    "abserr = abs.(y - x)              # Compute the absolute roundoff errors\n",
    "relerr = abserr./abs.(x)          # Compute the relative roundoff errors\n",
    "\n",
    "using PyPlot\n",
    "subplot(1, 2, 1)\n",
    "plot(x, abserr)\n",
    "axis([minimum(x), maximum(x), minimum(abserr), maximum(abserr)])\n",
    "title(\"absolute error\")\n",
    "\n",
    "subplot(1, 2, 2)\n",
    "plot(x, relerr)\n",
    "plot(x, η*ones(length(x)), \"r\")\n",
    "axis([minimum(x), maximum(x), minimum(abserr), maximum(abserr)])\n",
    "title(\"relative error\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rounding(Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RoundingMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "?setrounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default rounding mode is `RoundNearest` (round to the nearest floating-point number). This implies that\n",
    "\n",
    "$$ \\frac{|x - \\mathrm{fl}(x)|}{|x|} \\leq \\frac{1}{2} 2^{-52} = \\eta.$$\n",
    "\n",
    "If `RoundToZero` is used (a.k.a. **chopping**), then\n",
    "\n",
    "$$ \\frac{|x - \\mathrm{fl}(x)|}{|x|} \\leq 2^{-52} = 2 \\eta.$$\n",
    "\n",
    "`RoundNearest` is used since it produces smaller roundoff errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundoff error accumulation\n",
    "\n",
    "When performing arithmetic operations on floats, extra **guard digits** are used to ensure **exact rounding**. This guarantees that the relative error of a floating-point operation (**flop**) is small. More precisely, for floating-point numbers $x$ and $y$, we have\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\mathrm{fl}(x \\pm y) &= (x \\pm y)(1 + \\varepsilon_1) \\\\\n",
    "\\mathrm{fl}(x \\times y) &= (x \\times y)(1 + \\varepsilon_2) \\\\\n",
    "\\mathrm{fl}(x \\div y) &= (x \\div y)(1 + \\varepsilon_3) \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "where $|\\varepsilon_i| \\leq \\eta$, for $i = 1,2,3$, where $\\eta$ is the unit roundoff.\n",
    "\n",
    "Although the relative error of each flop is small, it is possible to have the roundoff error accumulate and create significant error in the final result. If $E_n$ is the error after $n$ flops, then:\n",
    "\n",
    "- **linear roundoff error accumulation** is when $E_n \\approx c_0 n E_0$\n",
    "- **exponential roundoff error accumulation** is when $E_n \\approx c_1^n E_0$, for some $c_1 > 1$\n",
    "\n",
    "In general, linear roundoff error accumulation is unavoidable. On the other hand, exponential roundoff error accumulation is not acceptable and is an indication of an **unstable algorithm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General advice\n",
    "\n",
    "1. Adding $x + y$ when $|x| \\gg |y|$ can cause the information in $y$ to be 'lost' in the summation.\n",
    "\n",
    "2. Dividing by very small numbers or multiplying by very large numbers can greatly **magnify error**.\n",
    "\n",
    "3. Subtracting numbers that are almost equal produces **cancellation error**.\n",
    "\n",
    "4. An **overflow** occurs when the result is too large in magnitude to be representable as a float. Result will become either `Inf` or `-Inf`. Overflows should be avoided.\n",
    "\n",
    "4. An **underflow** occurs when the result is too small in magnitude to be representable as a float. Result will become either `0.0` or `-0.0`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (summation order)\n",
    "\n",
    "This next example shows that summation order can make a difference. We will compute\n",
    "\n",
    "$$\n",
    "s = \\sum_{n = 1}^{1,000,000} \\frac{1}{n}\n",
    "$$\n",
    "\n",
    "in two different ways: from largest to smallest and from smallest to largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# We will use Float32 to emphasize the loss of accuracy.\n",
    "\n",
    "# Summing from largest to smallest:  n = 1, 2, ..., 1000000\n",
    "badsum = Float32(0.0)\n",
    "for n = 1:1000000\n",
    "    badsum += Float32(1/n)\n",
    "end\n",
    "println(badsum, \" (badsum)\")\n",
    "\n",
    "# Summing from smallest to largest:  n = 1000000, 999999, ..., 1\n",
    "goodsum = Float32(0.0)\n",
    "for n = 1000000:-1:1\n",
    "    goodsum += Float32(1/n)\n",
    "end\n",
    "println(goodsum, \" (goodsum)\")\n",
    "\n",
    "# The 'exact' answer using BigFloat extended precision (slow)\n",
    "s = big(0.0)\n",
    "for n = 1000000:-1:1\n",
    "    s += big(1/n)\n",
    "end\n",
    "truesum = Float32(s)\n",
    "println(truesum, \" (truesum)\")\n",
    "\n",
    "println(abs(truesum - badsum), \" (badsum error)\")\n",
    "println(abs(truesum - goodsum), \" (goodsum error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (cancellation error)\n",
    "\n",
    "It is easy to show that \n",
    "\n",
    "$$\n",
    "\\ln\\left( x - \\sqrt{x^2-1} \\right) = -\\ln\\left( x + \\sqrt{x^2-1} \\right).\n",
    "$$\n",
    "\n",
    "Indeed,\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\ln\\left( x - \\sqrt{x^2-1} \\right) \n",
    "& = \\ln\\left( \\frac{x - \\sqrt{x^2-1}}{1} \\cdot \\frac{x + \\sqrt{x^2-1}}{x + \\sqrt{x^2-1}} \\right) \\\\\n",
    "& = \\ln\\left( \\frac{x^2 - \\left(x^2-1\\right)}{x + \\sqrt{x^2-1}} \\right) \\\\\n",
    "& = \\ln\\left( \\frac{1}{x + \\sqrt{x^2-1}} \\right) \\\\\n",
    "& = -\\ln\\left( x + \\sqrt{x^2-1} \\right). \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Which formula is more suitable for numerical computation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = 1e6\n",
    "\n",
    "badres  =  log(x - sqrt(x^2 - 1))\n",
    "goodres = -log(x + sqrt(x^2 - 1))\n",
    "\n",
    "x = big(x)\n",
    "trueres = Float64(-log(x + sqrt(x^2 - 1)))\n",
    "\n",
    "println(badres, \" (badres)\")\n",
    "println(goodres, \" (goodres)\")\n",
    "println(trueres, \" (trueres)\")\n",
    "\n",
    "println(abs(badres - trueres)/abs(trueres), \" (badres error)\")\n",
    "println(abs(goodres - trueres)/abs(trueres), \" (goodres error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (avoiding overflow)\n",
    "\n",
    "Overflow is possible when squaring a large number. This needs to be avoided when computing the Euclidean norm (a.k.a. the $\\ell_2$-norm) of a vector $x$:\n",
    "\n",
    "$$\n",
    "\\|x\\|_2 = \\sqrt{x_1^2 + x_2^2 + \\cdots + x_n^2}.\n",
    "$$\n",
    "\n",
    "If some $x_i$ is very large, it is possible that $x_i^2$ will overflow, causing the final result to be `Inf`. We can avoid this as follows.\n",
    "\n",
    "Let \n",
    "$$\\bar{x} = \\max_{i=1:n} |x_i|.$$\n",
    "Then\n",
    "$$\n",
    "\\|x\\|_2 = \\bar{x} \\sqrt{\\left(\\frac{x_1}{\\bar{x}}\\right)^2 + \\left(\\frac{x_2}{\\bar{x}}\\right)^2 + \\cdots + \\left(\\frac{x_n}{\\bar{x}}\\right)^2}.\n",
    "$$\n",
    "Since $|x_i/\\bar{x}| \\leq 1$ for all $i$, no overflow will occur. Underflow may occur, but this is harmless.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "n = 100\n",
    "x = 10e200*rand(n)\n",
    "\n",
    "# Overflow occurs\n",
    "s = 0.0\n",
    "for i = 1:n\n",
    "    s += x[i]^2\n",
    "end\n",
    "badres = sqrt(s)\n",
    "println(\"badres = \", badres)\n",
    "\n",
    "# Overflow is avoided\n",
    "xbar = maximum(abs.(x))\n",
    "xscaled = x/xbar\n",
    "s = 0.0\n",
    "for i = 1:n\n",
    "    s += xscaled[i]^2\n",
    "end\n",
    "goodres = xbar*sqrt(s)\n",
    "println(\"goodres = \", goodres)\n",
    "\n",
    "# Use the built-in norm function to check\n",
    "println(\"norm(x) = \", norm(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
